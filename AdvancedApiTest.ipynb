{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8aa8a63-af52-4712-93c7-b76aa25dfcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\aless\\anaconda3\\envs\\project-s-env\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aless\\anaconda3\\envs\\project-s-env\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aless\\anaconda3\\envs\\project-s-env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aless\\anaconda3\\envs\\project-s-env\\lib\\site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\aless\\anaconda3\\envs\\project-s-env\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\aless\\anaconda3\\envs\\project-s-env\\lib\\site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aless\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\aless\\anaconda3\\envs\\project-s-env\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\aless\\anaconda3\\envs\\project-s-env\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\aless\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aless\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q openai networkx\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139815e1-07c7-4472-9e65-2d5baefe3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b06039ea-7d8d-4573-af36-dcea8a2e3bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e84066d-13f4-4b66-962f-26e8801cd267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "openai = OpenAI(api_key=api_key)\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": \"What is 2+2?\"}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f698f38-c8b0-4d9c-9c3c-5b3a0446184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4317e991-18f9-49a1-99b8-d496364a4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenPredictor:\n",
    "    def __init__(self, client, model_name: str, temperature: int):\n",
    "        self.client = client\n",
    "        self.messages = []\n",
    "        self.predictions = []\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def predict_tokens(self, prompt: str, max_tokens: int = 100) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Generate text token by token and track prediction probabilities.\n",
    "        Returns list of predictions with top token and alternatives.\n",
    "        \"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=self.temperature,\n",
    "            logprobs=True,\n",
    "            seed=42,\n",
    "            top_logprobs=7,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        predictions = []\n",
    "        for chunk in response:\n",
    "            if chunk.choices[0].delta.content:\n",
    "                token = chunk.choices[0].delta.content\n",
    "                logprobs = chunk.choices[0].logprobs.content[0].top_logprobs\n",
    "                logprob_dict = {item.token: item.logprob for item in logprobs}\n",
    "\n",
    "                # Get top predicted token and probability\n",
    "                top_token = token\n",
    "                top_prob = logprob_dict[token]\n",
    "\n",
    "                # Get alternative predictions\n",
    "                alternatives = []\n",
    "                for alt_token, alt_prob in logprob_dict.items():\n",
    "                    if alt_token != token:\n",
    "                        alternatives.append((alt_token, math.exp(alt_prob)))\n",
    "                alternatives.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                prediction = {'token': top_token, 'probability': math.exp(top_prob),'alternatives': alternatives[:3]}\n",
    "                predictions.append(prediction)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cfcff61-2614-4305-8035-7524ad182bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-4o-mini\"\n",
    "temperature = 0.0\n",
    "\n",
    "predictor = TokenPredictor(openai, model_name, temperature)\n",
    "prompt = \"I feel lonely. Reply in 1 short sentence.\"\n",
    "predictions = predictor.predict_tokens(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfecca30-214d-4584-890b-8cac0a31040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d07fc4b-62d5-41da-b572-18119a17d44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'alternatives': [(\"You're\", 0.21435394506452804),\n",
      "                   (\"It's\", 0.16693902027069935),\n",
      "                   ('I', 0.015527745848756037)],\n",
      "  'probability': 0.582674433727415,\n",
      "  'token': \"I'm\"},\n",
      " {'alternatives': [(' sorry', 0.07577578028593854),\n",
      "                   (' really', 0.0010808834546355618),\n",
      "                   (' truly', 3.898272562976294e-06)],\n",
      "  'probability': 0.9231378962881625,\n",
      "  'token': ' here'},\n",
      " {'alternatives': [(' to', 0.06007491717047663),\n",
      "                   (' if', 0.0001687379981244691),\n",
      "                   (',', 1.3850858343846484e-05)],\n",
      "  'probability': 0.9397297377540044,\n",
      "  'token': ' for'},\n",
      " {'alternatives': [(' support', 3.398267819495071e-09),\n",
      "                   ('你', 2.335593038799337e-09),\n",
      "                   ('you', 2.061153622438558e-09)],\n",
      "  'probability': 1.0,\n",
      "  'token': ' you'},\n",
      " {'alternatives': [('—', 0.38699359425390156),\n",
      "                   (',', 0.11087553432530178),\n",
      "                   (' if', 0.001792136099027015)],\n",
      "  'probability': 0.4969096111173527,\n",
      "  'token': ';'},\n",
      " {'alternatives': [(\" it's\", 0.10608253000767752),\n",
      "                   (' you', 0.05678188655281812),\n",
      "                   (\" let's\", 0.03039315371026467)],\n",
      "  'probability': 0.7838498120643116,\n",
      "  'token': \" you're\"},\n",
      " {'alternatives': [(' never', 0.00026118955032221623),\n",
      "                   (' definitely', 2.2597323796279538e-06),\n",
      "                   ('not', 7.73238636605596e-08)],\n",
      "  'probability': 0.9997361956863916,\n",
      "  'token': ' not'},\n",
      " {'alternatives': [(' truly', 8.315271330899149e-07),\n",
      "                   (' as', 6.47593982395546e-07),\n",
      "                   ('alone', 1.8553878237411744e-07)],\n",
      "  'probability': 0.9999980183344259,\n",
      "  'token': ' alone'},\n",
      " {'alternatives': [(' in', 0.2689086095747055),\n",
      "                   ('!', 0.00011583033624672062),\n",
      "                   (',', 2.7240684102664557e-06)],\n",
      "  'probability': 0.7309693869231101,\n",
      "  'token': '.'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f23be19-ced7-4e27-a1ba-75d1b2d1985e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project-s-env)",
   "language": "python",
   "name": "project-s-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
